{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2b7dbd-0aa1-43f4-824a-9a08988a62fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 12:27:12.688268: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-09-20 12:27:12.688290: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-09-20 12:27:12.688297: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-09-20 12:27:12.688354: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-09-20 12:27:12.688509: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "2023-09-20 12:27:14.311 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/kayle/miniforge3/envs/mldev/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = load_model(\"model.h5\")\n",
    "\n",
    "# Define class labels (you might need to adjust these according to your dataset)\n",
    "class_labels = ['class1', 'class2'] # Replace with your actual class labels\n",
    "\n",
    "st.title('Image Classification App')\n",
    "st.write('Upload an image for classification')\n",
    "\n",
    "uploaded_image = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_image is not None:\n",
    "    image_to_predict = image.load_img(uploaded_image, target_size=(224, 224))\n",
    "    st.image(image_to_predict, caption='Uploaded Image', use_column_width=True)\n",
    "\n",
    "    if st.button('Predict'):\n",
    "        img_array = image.img_to_array(image_to_predict)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "        st.write(f'Predicted Class: {class_labels[predicted_class[0]]}')\n",
    "        st.write(f'Prediction Scores: {predictions[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35b99a-02e3-48ab-a9d7-be21a29059f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.50.51.183:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "[IPKernelApp] ERROR | Unable to initialize signal:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kayle/miniforge3/envs/mldev/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 698, in initialize\n",
      "    self.init_signal()\n",
      "  File \"/Users/kayle/miniforge3/envs/mldev/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 542, in init_signal\n",
      "    signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
      "  File \"/Users/kayle/miniforge3/envs/mldev/lib/python3.10/signal.py\", line 56, in signal\n",
      "    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))\n",
      "ValueError: signal only works in main thread of the main interpreter\n"
     ]
    }
   ],
   "source": [
    "!streamlit run /Users/kayle/miniforge3/envs/mldev/lib/python3.10/site-packages/ipykernel_launcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb8039-78e8-4d8d-929d-0e6898d7bc70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
